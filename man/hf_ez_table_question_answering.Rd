% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ez.R
\name{hf_ez_table_question_answering}
\alias{hf_ez_table_question_answering}
\title{Answer Questions about a Data Table}
\usage{
hf_ez_table_question_answering(
  model_id = "google/tapas-base-finetuned-wtq",
  use_api = FALSE
)
}
\arguments{
\item{model_id}{A model_id. Run hf_search_models(...) for model_ids. Defaults to 'google/tapas-base-finetuned-wtq'.}

\item{use_api}{Whether to use the Inference API to run the model (TRUE) or download and run the model locally (FALSE). Defaults to FALSE}
}
\value{
A table question answering object
}
\description{
Don’t know SQL? Don’t want to dive into a large spreadsheet? Ask questions in plain english!
}
\examples{
\dontrun{
# Create a table to query
qa_table <-
  tibble::tibble(Repository = c('Transformers', 'Datasets', 'Tokenizers'),
                 Stars = c('36542', '4512', '3934'),
                 Contributors = c('651', '77', '34'),
                 Programming.language = c('Python', 'Python', 'Rust, Python and NodeJS'))

# Load the default model and use local inference
ez_model <- hf_ez_table_question_answering()
ez_model$infer(query = "How many stars does the transformers repository have?", table = qa_table)

# Use the api for inference.
ez_model <- hf_ez_fill_mask(use_api = TRUE)
ez_model$infer(query = "How many stars does the transformers repository have?", table = qa_table)
}
}
\seealso{
\url{https://huggingface.co/docs/api-inference/detailed_parameters#table-question-answering-task}
}
