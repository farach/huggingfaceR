% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generate.R
\name{hf_generate}
\alias{hf_generate}
\title{Text Generation}
\usage{
hf_generate(
  prompt,
  model = "HuggingFaceTB/SmolLM3-3B",
  max_new_tokens = 50,
  temperature = 1,
  top_p = NULL,
  token = NULL,
  ...
)
}
\arguments{
\item{prompt}{Character vector of text prompt(s) to generate from.}

\item{model}{Character string. Model ID from Hugging Face Hub.
Default: "HuggingFaceTB/SmolLM3-3B".}

\item{max_new_tokens}{Integer. Maximum number of tokens to generate. Default: 50.}

\item{temperature}{Numeric. Sampling temperature (0-2). Default: 1.0.}

\item{top_p}{Numeric. Nucleus sampling parameter. Default: NULL.}

\item{token}{Character string or NULL. API token for authentication.}

\item{...}{Additional parameters passed to the model.}
}
\value{
A tibble with columns: prompt, generated_text
}
\description{
Generate text from a prompt using a language model via the Inference Providers API.
}
\examples{
\dontrun{
# Simple text generation
hf_generate("Once upon a time in a land far away,")

# With different model
hf_generate("The future of AI is", model = "meta-llama/Llama-3-8B-Instruct:together")
}
}
