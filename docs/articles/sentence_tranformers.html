<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction To Sentence Transformers • huggingfaceR</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction To Sentence Transformers">
<meta property="og:description" content="huggingfaceR">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">huggingfaceR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/huggingface_hub.html">The Hugging Face Hub</a>
    </li>
    <li>
      <a href="../articles/introduction_to_models.html">Introduction To Models</a>
    </li>
    <li>
      <a href="../articles/introduction_to_pipelines.html">Introduction To Pipelines</a>
    </li>
    <li>
      <a href="../articles/sentence_tranformers.html">Introduction To Sentence Transformers</a>
    </li>
    <li>
      <a href="../articles/tokenizers.html">Introduction To Tokenizers</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction To Sentence Transformers</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/farach/huggingfaceR/vignettes/sentence_tranformers.Rmd" class="external-link"><code>vignettes/sentence_tranformers.Rmd</code></a></small>
      <div class="hidden name"><code>sentence_tranformers.Rmd</code></div>

    </div>

    
    
<p>Aside from wrapping Hugging Face’s <code>transformers</code> library,
<code>huggingfaceR</code> also wraps around the
<code>sentence_transformers</code> library to allow SOTA document
embeddings.</p>
<div class="section level2">
<h2 id="initiating-a-sentence-transformers-pipeline">Initiating a Sentence Transformers Pipeline<a class="anchor" aria-label="anchor" href="#initiating-a-sentence-transformers-pipeline"></a>
</h2>
<p>It’s incredibly simple to use <code>sentence_transformers</code> in
<code>huggingfaceR</code>. You just need one function:
<code>hf_load_sentence_model</code> and a model_id. To begin with, we’ll
use the ‘paraphrase-MiniLM-L6-v2’ as our model:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_id</span> <span class="op">&lt;-</span> <span class="st">"paraphrase-MiniLM-L6-v2"</span></span>
<span></span>
<span><span class="va">minilm_l6</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hf_load_sentence_model.html">hf_load_sentence_model</a></span><span class="op">(</span><span class="va">model_id</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="extracting-documentsentence-embeddings-with-encode">Extracting document/sentence embeddings with encode<a class="anchor" aria-label="anchor" href="#extracting-documentsentence-embeddings-with-encode"></a>
</h3>
<p>The first, and for many the only, thing a user will want to do is
feed in some document(s) and receive the embedding(s). We can do that by
using R’s <code>$</code> syntax to access our sentence transformer’s
<code>encode</code> class method - if unfamiliar with OOP/Python, just
think of class methods as functions.</p>
<p>But first, we’ll need a document:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">document</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Many people think Lionel Messi is the greatest footballer to have ever played the Beautiful Game."</span><span class="op">)</span></span>
<span></span>
<span><span class="va">embedding</span> <span class="op">&lt;-</span> <span class="va">minilm_l6</span><span class="op">$</span><span class="fu">encode</span><span class="op">(</span><span class="va">document</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="tidying-the-output">Tidying the output<a class="anchor" aria-label="anchor" href="#tidying-the-output"></a>
</h3>
<p>Calling our model on one document returns a 384 length vector. We
could tidy it into a tibble by first transposing:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">embedding</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span>  <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if</span></span>
<span><span class="co">#&gt; `.name_repair` is omitted as of tibble 2.0.0.</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Using compatibility `.name_repair`.</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 1 × 384</span></span></span>
<span><span class="co">#&gt;       V1    V2    V3     V4    V5     V6    V7    V8    V9   V10    V11    V12</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span> 0.085<span style="text-decoration: underline;">3</span> 0.296 0.103 -<span style="color: #BB0000;">0.800</span> 0.101 0.044<span style="text-decoration: underline;">8</span> 0.103 0.399 0.127 0.179 -<span style="color: #BB0000;">0.703</span> -<span style="color: #BB0000;">0.520</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># … with 372 more variables: V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V29 &lt;dbl&gt;, V30 &lt;dbl&gt;, V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V35 &lt;dbl&gt;, V36 &lt;dbl&gt;, V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V41 &lt;dbl&gt;, V42 &lt;dbl&gt;, V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V47 &lt;dbl&gt;, V48 &lt;dbl&gt;, V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;, …</span></span></span></code></pre></div>
<p>Most likely we’re not going to want to embed just one document, but
many. Let’s use <code><a href="https://stringr.tidyverse.org/reference/stringr-data.html" class="external-link">stringr::sentences</a></code> as a test run. There are
720 sentences which we’ll embed in one go. Because we’re embedding a
number of sentences, we’ll set <code>show_progress_bar = TRUE</code>,
we’ll also change the <code>batch_size to 64L</code> - although the
default setting of 32L would be fine too.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proc.time.html" class="external-link">proc.time</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">sentences_embeddings</span> <span class="op">&lt;-</span> <span class="va">minilm_l6</span><span class="op">$</span><span class="fu">encode</span><span class="op">(</span><span class="fu">stringr</span><span class="fu">::</span><span class="va"><a href="https://stringr.tidyverse.org/reference/stringr-data.html" class="external-link">sentences</a></span>,show_progress_bar <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                                         batch_size <span class="op">=</span> <span class="fl">64L</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/proc.time.html" class="external-link">proc.time</a></span><span class="op">(</span><span class="op">)</span> <span class="op">-</span> <span class="va">start</span></span>
<span><span class="co">#&gt;    user  system elapsed </span></span>
<span><span class="co">#&gt;  12.025   1.900   1.865</span></span></code></pre></div>
<p>The process took about 2 seconds start to finish, not bad! We can
tidy up our results similarly to before:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sentences_embeddings</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 384 × 720</span></span></span>
<span><span class="co">#&gt;         V1      V2      V3      V4      V5      V6      V7     V8     V9</span></span>
<span><span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> -<span style="color: #BB0000;">0.388</span>  -<span style="color: #BB0000;">0.581</span>  -<span style="color: #BB0000;">0.125</span>  -<span style="color: #BB0000;">0.290</span>   0.609  -<span style="color: #BB0000;">0.383</span>   0.143   0.264  0.386</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> -<span style="color: #BB0000;">0.201</span>   0.387   0.132  -<span style="color: #BB0000;">0.019</span><span style="color: #BB0000; text-decoration: underline;">9</span> -<span style="color: #BB0000;">0.191</span>  -<span style="color: #BB0000;">0.511</span>   0.324   0.196 -<span style="color: #BB0000;">0.202</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span>  0.425  -<span style="color: #BB0000;">0.111</span>  -<span style="color: #BB0000;">0.165</span>  -<span style="color: #BB0000;">0.375</span>  -<span style="color: #BB0000;">0.144</span>  -<span style="color: #BB0000;">0.439</span>  -<span style="color: #BB0000;">0.097</span><span style="color: #BB0000; text-decoration: underline;">9</span> -<span style="color: #BB0000;">0.104</span>  0.267</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> -<span style="color: #BB0000;">0.104</span>  -<span style="color: #BB0000;">0.363</span>  -<span style="color: #BB0000;">0.268</span>  -<span style="color: #BB0000;">0.558</span>  -<span style="color: #BB0000;">0.033</span><span style="color: #BB0000; text-decoration: underline;">7</span>  0.592  -<span style="color: #BB0000;">0.086</span><span style="color: #BB0000; text-decoration: underline;">1</span>  0.659  0.348</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> -<span style="color: #BB0000;">0.506</span>   0.196  -<span style="color: #BB0000;">0.153</span>  -<span style="color: #BB0000;">0.100</span>  -<span style="color: #BB0000;">0.028</span><span style="color: #BB0000; text-decoration: underline;">0</span>  0.297   0.938  -<span style="color: #BB0000;">0.415</span> -<span style="color: #BB0000;">0.141</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> -<span style="color: #BB0000;">0.243</span>   0.236  -<span style="color: #BB0000;">0.199</span>   0.051<span style="text-decoration: underline;">6</span>  0.216   0.378  -<span style="color: #BB0000;">0.216</span>  -<span style="color: #BB0000;">0.955</span> -<span style="color: #BB0000;">0.534</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> -<span style="color: #BB0000;">0.131</span>  -<span style="color: #BB0000;">0.399</span>  -<span style="color: #BB0000;">0.051</span><span style="color: #BB0000; text-decoration: underline;">5</span>  0.014<span style="text-decoration: underline;">8</span>  0.337   0.683   0.066<span style="text-decoration: underline;">4</span>  0.283 -<span style="color: #BB0000;">0.378</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span>  0.087<span style="text-decoration: underline;">7</span> -<span style="color: #BB0000;">0.050</span><span style="color: #BB0000; text-decoration: underline;">8</span> -<span style="color: #BB0000;">0.363</span>  -<span style="color: #BB0000;">0.103</span>  -<span style="color: #BB0000;">0.415</span>   0.113   0.033<span style="text-decoration: underline;">4</span> -<span style="color: #BB0000;">0.205</span> -<span style="color: #BB0000;">1.07</span> </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> -<span style="color: #BB0000;">0.016</span><span style="color: #BB0000; text-decoration: underline;">4</span> -<span style="color: #BB0000;">0.020</span><span style="color: #BB0000; text-decoration: underline;">4</span> -<span style="color: #BB0000;">0.392</span>   0.277  -<span style="color: #BB0000;">0.023</span><span style="color: #BB0000; text-decoration: underline;">3</span>  0.020<span style="text-decoration: underline;">1</span> -<span style="color: #BB0000;">0.083</span><span style="color: #BB0000; text-decoration: underline;">6</span> -<span style="color: #BB0000;">0.271</span>  0.121</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span>  0.194   0.224   0.127  -<span style="color: #BB0000;">0.591</span>  -<span style="color: #BB0000;">0.356</span>  -<span style="color: #BB0000;">0.567</span>  -<span style="color: #BB0000;">0.248</span>   0.117 -<span style="color: #BB0000;">0.299</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># … with 374 more rows, and 711 more variables: V10 &lt;dbl&gt;, V11 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;, V17 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;, V23 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V30 &lt;dbl&gt;, V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V36 &lt;dbl&gt;, V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   V42 &lt;dbl&gt;, V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;, V47 &lt;dbl&gt;, …</span></span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="using-torch-to-send-the-model-to-the-gpu">Using Torch to send the model to the GPU<a class="anchor" aria-label="anchor" href="#using-torch-to-send-the-model-to-the-gpu"></a>
</h3>
<p>However, when dealing with more and longer documents, or when using a
larger model, the proces can take significantly longer. In such cases,
it’s a good idea to use a GPU if you have access to one. The author is
currently using a Macbook with an M1 chip. There is ongoing work by the
Pytorch team to accelerate MPS chips, currently we can send some models
to our GPU and some not - most Hugging Face models require
<code>aten::cumsum.out</code> for which the backend integration with
Apple Silicon chips has not yet been written. The process ought to be
similar, and simpler with an NVIDIA/Cuda GPU.</p>
<p>You will need to have the appropriate torch version installed for you
GPU.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">reticulate</span><span class="fu">::</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/py_run.html" class="external-link">py_run_string</a></span><span class="op">(</span><span class="st">"import torch"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">device</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hf_set_device.html">hf_set_device</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">minilm_gpu</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hf_load_sentence_model.html">hf_load_sentence_model</a></span><span class="op">(</span><span class="va">model_id</span><span class="op">)</span></span>
<span><span class="va">minilm_gpu</span><span class="op">$</span><span class="fu">to</span><span class="op">(</span><span class="va">device</span><span class="op">)</span></span>
<span><span class="co">#&gt; SentenceTransformer(</span></span>
<span><span class="co">#&gt;   (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel </span></span>
<span><span class="co">#&gt;   (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})</span></span>
<span><span class="co">#&gt; )</span></span></code></pre></div>
<p>Now we’re ready to call our model with GPU acceleration:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sentences_embeddings_gpu</span> <span class="op">&lt;-</span> <span class="va">minilm_gpu</span><span class="op">$</span><span class="fu">encode</span><span class="op">(</span><span class="fu">stringr</span><span class="fu">::</span><span class="va"><a href="https://stringr.tidyverse.org/reference/stringr-data.html" class="external-link">sentences</a></span>, device <span class="op">=</span> <span class="va">device</span>, show_progress_bar <span class="op">=</span> <span class="cn">TRUE</span>, batch_size <span class="op">=</span> <span class="fl">64L</span><span class="op">)</span></span></code></pre></div>
<p>You’ll notice that it actually takes longer with the GPU - that’s
because of the set up costs involved. With a larger dataset or model you
should expect to see at least a 3x speed up when using an M1 chip, and
more with an NVIDIA/cuda gpu (depending on hardware of course).</p>
<p>Let’s say you wanted a different model to “paraphrase-MiniLM-L6-v2”.
You could use <code><a href="../reference/models_with_downloads.html">huggingfaceR::models_with_downloads</a></code> to select
a model based on downloads:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">models_with_downloads</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">task</span> <span class="op">==</span> <span class="st">"sentence-similarity"</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 556 × 5</span></span></span>
<span><span class="co">#&gt;    model                                           downloads task  sha   private</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                                               <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> sentence-transformers/stsb-distilbert-base        2<span style="text-decoration: underline;">128</span>296 sent… 815b… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> sentence-transformers/all-MiniLM-L6-v2            1<span style="text-decoration: underline;">952</span>830 sent… 3746… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> sentence-transformers/paraphrase-MiniLM-L6-v2     1<span style="text-decoration: underline;">811</span>338 sent… 68b9… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> sentence-transformers/bert-base-nli-mean-tokens   1<span style="text-decoration: underline;">346</span>920 sent… 18fc… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> sentence-transformers/paraphrase-multilingual-…    <span style="text-decoration: underline;">707</span>910 sent… b8ef… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> sentence-transformers/all-mpnet-base-v2            <span style="text-decoration: underline;">661</span>825 sent… 86eb… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> sentence-transformers/distiluse-base-multiling…    <span style="text-decoration: underline;">526</span>976 sent… 896f… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> sentence-transformers/all-MiniLM-L12-v2            <span style="text-decoration: underline;">388</span>231 sent… 2e5b… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> sentence-transformers/paraphrase-mpnet-base-v2     <span style="text-decoration: underline;">324</span>132 sent… 18df… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> sentence-transformers/paraphrase-xlm-r-multili…    <span style="text-decoration: underline;">244</span>071 sent… 50f7… FALSE  </span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># … with 546 more rows</span></span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="instantiating-a-more-powerful-model">Instantiating a more powerful model<a class="anchor" aria-label="anchor" href="#instantiating-a-more-powerful-model"></a>
</h3>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_id</span> <span class="op">&lt;-</span> <span class="st">"sentence-transformers/stsb-distilbert-base"</span></span>
<span><span class="va">st_distilbert</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hf_load_sentence_model.html">hf_load_sentence_model</a></span><span class="op">(</span><span class="va">model_id</span><span class="op">)</span></span></code></pre></div>
<p>And you could extract embeddings using the same methods as before.
Note if using RStudio - when calling model$encode() you can use tab to
access available arguments.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">st_embeddings</span> <span class="op">&lt;-</span> <span class="va">st_distilbert</span><span class="op">$</span><span class="fu">encode</span><span class="op">(</span><span class="fu">stringr</span><span class="fu">::</span><span class="va"><a href="https://stringr.tidyverse.org/reference/stringr-data.html" class="external-link">sentences</a></span>, show_progress_bar <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>Voila, for most use cases you should be covered.</p>
</div>
</div>
<div class="section level2">
<h2 id="advanced-users">Advanced Users<a class="anchor" aria-label="anchor" href="#advanced-users"></a>
</h2>
<p>Let’s take a step back, we can use R’s familiar <code>$</code> syntax
to access our model’s class methods and config.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">minilm_l6</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] "add_module"                         "append"                            </span></span>
<span><span class="co">#&gt;  [3] "apply"                              "bfloat16"                          </span></span>
<span><span class="co">#&gt;  [5] "buffers"                            "children"                          </span></span>
<span><span class="co">#&gt;  [7] "cpu"                                "cuda"                              </span></span>
<span><span class="co">#&gt;  [9] "device"                             "double"                            </span></span>
<span><span class="co">#&gt; [11] "dump_patches"                       "encode"                            </span></span>
<span><span class="co">#&gt; [13] "encode_multi_process"               "eval"                              </span></span>
<span><span class="co">#&gt; [15] "evaluate"                           "extra_repr"                        </span></span>
<span><span class="co">#&gt; [17] "fit"                                "float"                             </span></span>
<span><span class="co">#&gt; [19] "forward"                            "get_buffer"                        </span></span>
<span><span class="co">#&gt; [21] "get_extra_state"                    "get_max_seq_length"                </span></span>
<span><span class="co">#&gt; [23] "get_parameter"                      "get_sentence_embedding_dimension"  </span></span>
<span><span class="co">#&gt; [25] "get_sentence_features"              "get_submodule"                     </span></span>
<span><span class="co">#&gt; [27] "half"                               "ipu"                               </span></span>
<span><span class="co">#&gt; [29] "load"                               "load_state_dict"                   </span></span>
<span><span class="co">#&gt; [31] "max_seq_length"                     "modules"                           </span></span>
<span><span class="co">#&gt; [33] "named_buffers"                      "named_children"                    </span></span>
<span><span class="co">#&gt; [35] "named_modules"                      "named_parameters"                  </span></span>
<span><span class="co">#&gt; [37] "parameters"                         "register_backward_hook"            </span></span>
<span><span class="co">#&gt; [39] "register_buffer"                    "register_forward_hook"             </span></span>
<span><span class="co">#&gt; [41] "register_forward_pre_hook"          "register_full_backward_hook"       </span></span>
<span><span class="co">#&gt; [43] "register_load_state_dict_post_hook" "register_module"                   </span></span>
<span><span class="co">#&gt; [45] "register_parameter"                 "requires_grad_"                    </span></span>
<span><span class="co">#&gt; [47] "save"                               "save_to_hub"                       </span></span>
<span><span class="co">#&gt; [49] "set_extra_state"                    "share_memory"                      </span></span>
<span><span class="co">#&gt; [51] "smart_batching_collate"             "start_multi_process_pool"          </span></span>
<span><span class="co">#&gt; [53] "state_dict"                         "stop_multi_process_pool"           </span></span>
<span><span class="co">#&gt; [55] "T_destination"                      "to"                                </span></span>
<span><span class="co">#&gt; [57] "to_empty"                           "tokenize"                          </span></span>
<span><span class="co">#&gt; [59] "tokenizer"                          "train"                             </span></span>
<span><span class="co">#&gt; [61] "training"                           "type"                              </span></span>
<span><span class="co">#&gt; [63] "xpu"                                "zero_grad"</span></span></code></pre></div>
<p>Our original model outputs 384 dimensional embeddings, and accepts up
to 128 tokens:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">minilm_l6</span><span class="op">$</span><span class="fu">get_sentence_embedding_dimension</span><span class="op">(</span><span class="op">)</span>,<span class="va">minilm_l6</span><span class="op">$</span><span class="va">max_seq_length</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 384 128</span></span></code></pre></div>
<p>Our next model outputs 768 dimensional embeddings and also accepts up
to 128 tokens:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">st_distilbert</span><span class="op">$</span><span class="fu">get_sentence_embedding_dimension</span><span class="op">(</span><span class="op">)</span>, <span class="va">st_distilbert</span><span class="op">$</span><span class="va">max_seq_length</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 768 128</span></span></code></pre></div>
<p>There’s a lot you can do/look at - for example you can get your
model’s tokenizer’s full vocabulary:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_vocab</span> <span class="op">&lt;-</span> <span class="va">st_distilbert</span><span class="op">$</span><span class="va">tokenizer</span><span class="op">$</span><span class="va">vocab</span></span>
<span></span>
<span><span class="va">model_vocab_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>  token <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">model_vocab</span><span class="op">)</span>,</span>
<span>  id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unlist.html" class="external-link">unlist</a></span><span class="op">(</span><span class="va">model_vocab</span>, recursive <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_vocab_df</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 30,522 × 2</span></span></span>
<span><span class="co">#&gt;    token            id</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>         <span style="color: #949494; font-style: italic;">&lt;int&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> ##ffer        <span style="text-decoration: underline;">12</span>494</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> ##itor        <span style="text-decoration: underline;">15</span>660</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> ぬ             <span style="text-decoration: underline;">1</span>669</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> adjusted      <span style="text-decoration: underline;">10</span>426</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 650           <span style="text-decoration: underline;">13</span>757</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> skulls        <span style="text-decoration: underline;">21</span>542</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> rudy          <span style="text-decoration: underline;">18</span>254</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> ineffective   <span style="text-decoration: underline;">20</span>694</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> ##pper        <span style="text-decoration: underline;">18</span>620</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> schizophrenia <span style="text-decoration: underline;">23</span>683</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># … with 30,512 more rows</span></span></span></code></pre></div>
<p>The possibilities are (almost) endless.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Alex Farach, Sam Terfa, Jack Penzer.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
